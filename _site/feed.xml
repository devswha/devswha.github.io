<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-08-17T20:57:34+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">AI 친구 만들기 대작전</title><subtitle>devswha blog</subtitle><author><name>Sangwoo Ha</name><email>devswha@gmail.com</email></author><entry><title type="html">큰 수의 법칙</title><link href="http://localhost:4000/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%ED%81%B0-%EC%88%98%EC%9D%98-%EB%B2%95%EC%B9%99/" rel="alternate" type="text/html" title="큰 수의 법칙" /><published>2024-08-15T00:00:00+09:00</published><updated>2024-08-17T00:00:00+09:00</updated><id>http://localhost:4000/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%ED%81%B0%20%EC%88%98%EC%9D%98%20%EB%B2%95%EC%B9%99</id><content type="html" xml:base="http://localhost:4000/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%ED%81%B0-%EC%88%98%EC%9D%98-%EB%B2%95%EC%B9%99/"><![CDATA[<h3 id="-문제">🔔 문제</h3>

<p>‘큰 수의 법칙’은 일반적으로 통계 분야에서 다루어지는 내용이지만 동빈이는 본인만의 방식으로 다르게 사용하고 있다. 동빈이의 큰 수의 법칙은 다양한 수로 이루어진 배열이 있을 때 주어진 수들을 M번 더하여 가장 큰 수를 만드는 법칙이다. 단, 배열의 특정한 인덱스(번호)에 해당하는 수가 연속해서 K번을 초과하여 더해질 수 없는 것이 이 법칙의 특징이다.</p>

<p>예를 들어 순서대로 2,4,5,4,6으로 이루어진 배열이 있을 때 M이 8이고, K가 3이라고 가정하자. 이 경우 특정한 인덱스의 수가 연속해서 세 번까지만 더해질 수 있으므로 큰 수의 법칙에 따른 결과는 6+6+6+5+6+6+6+5인 46이 된다.</p>

<p>단, 서로 다른 인덱스에 해당하는 수가 같은 경우에도 서로 다른 것으로 간주한다. 예를 들어 순서대로 3,4,3,4,3으로 이루어진 배열이 있을 때 M이 7이고, K가 2라고 가정하자. 이 경우 두 번째 원소에 해당하는 4와 네 번재 원소에 해당하는 4를 번갈아 두 번씩 더하는 것이 가능하다. 결과적으로 4+4+4+4+4+4+4인 28이 도출된다. 배열의 크기 N, 숫자가 더해지는 횟수 M, 그리고 K가 주어질 때 동빈이의 큰 수의 법칙에 따른 결과를 출력하시오.</p>

<h3 id="입력">입력</h3>

<p>첫째 줄에 N(2&lt;=N&lt;=1,000), M(1&lt;=M&lt;=10,000), K(1&lt;=K&lt;=10,000)의 자연수가 주어지며, 각 자연수는 공백으로 구분한다.</p>

<p>둘째 줄에 N개의 자연수가 주어진다. 각 자연수는 공백으로 구분한다. 단, 각각의 자연수는 1이상 10,000 이하의 수로 주어진다.</p>

<p>입력으로 주어지는 K는 항상 M보다 작거나 같다.</p>

<h3 id="출력">출력</h3>

<p>첫째 줄에 동빈이의 큰 수의 법칙에 따라 더해진 답을 출력한다.</p>

<h3 id="입출력-예시">입출력 예시</h3>
<p>5 8 3
2 4 5 4 6
출력: 46</p>

<h3 id="-풀이방법">🎯 풀이방법</h3>

<p>이 문제를 해결하려면 일단 입력값 중에서 가장 큰 수와 두 번째로 큰 수만 저장하면 된다. 연속으로 더할 수 있는 횟수는 최대 K번이므로  ‘가장 큰 수를 K번 더하고 두번째로 큰 수를 한 번 더하는 연산’을 반복하면 된다.</p>

<h3 id="예시-설명">예시 설명</h3>
<p>첫째 줄 입력: N(배열의 크기), M(몇번 더 할건지), K(한 숫자당 최대 연속으로 사용 가능한 개수) -&gt; 5, 8, 3
두번째 줄 입력: N 개의 자연수 -&gt; 2 4 5 4 6
8번 더하고, 최대 3개까지 가능하므로 가장 큰 순서대로 6+6+6+5+6+6+6+5 = 46</p>

<h3 id="-python-코드">💻 Python 코드</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">input</span><span class="p">().</span><span class="n">split</span><span class="p">())</span> <span class="c1"># 배열 크기, 더해지는 횟수, 연속 몇번까지
</span><span class="n">numbers</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">input</span><span class="p">().</span><span class="n">split</span><span class="p">())),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">first</span> <span class="o">=</span> <span class="n">numbers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 가장 큰 수
</span><span class="n">second</span> <span class="o">=</span> <span class="n">numbers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 두번째로 큰 수
</span>
<span class="n">answer</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">m</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">answer</span> <span class="o">+=</span> <span class="n">first</span>
        <span class="n">m</span> <span class="o">-=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">m</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">answer</span> <span class="o">+=</span> <span class="n">second</span>
    <span class="n">m</span> <span class="o">-=</span> <span class="mi">1</span>

<span class="k">print</span><span class="p">(</span><span class="n">answer</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="-심화">💡 심화</h3>
<p>M의 크기가 100억 이상처럼 높은 숫자라면 while true 안의 m==0 이 될때까지 M 숫자만큼 연산이 반복된다. 하지만 반복되는 수열을 파악한다면, M번의 연산 없이 구현이 가능하다. 예시를 보면, 반복되는 수열이 [6,6,6,5] 가 반복이 된다. 
즉, 가장 큰 수를 X 라 하고 두 번째로 큰 수를 x 라 할 때, [X,X,X,x] 가 반복된다. 그렇다면 이 반복되는 수열의 횟수는 M / (K+1) 이 된다. 그리고 이 수열에서 가장 큰 숫자는 K번, 다음 큰 숫자는 1번 반복된다. 
따라서 가장 큰 수 X 가 나올 횟수는 (M/(K+1))*K + M%(K+1), 이 되고 이 횟수를 M 에서 뺀 것이 두 번째로 큰 수 x 가 나올 횟수이다. 이를 코드로 구현하면</p>

<h3 id="-개선된-python-코드">💻 개선된 Python 코드</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">input</span><span class="p">().</span><span class="n">split</span><span class="p">())</span>
<span class="n">numbers</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">input</span><span class="p">().</span><span class="n">split</span><span class="p">())),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">first</span> <span class="o">=</span> <span class="n">numbers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">second</span> <span class="o">=</span> <span class="n">numbers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">m</span><span class="o">/</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">k</span>
<span class="n">count</span> <span class="o">+=</span> <span class="n">m</span><span class="o">%</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="n">answer</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">answer</span> <span class="o">+=</span> <span class="n">count</span> <span class="o">*</span> <span class="n">first</span>
<span class="n">answer</span> <span class="o">+=</span> <span class="p">(</span><span class="n">m</span><span class="o">-</span><span class="n">count</span><span class="p">)</span> <span class="o">*</span> <span class="n">second</span>

<span class="k">print</span><span class="p">(</span><span class="n">answer</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name>Sangwoo Ha</name><email>devswha@gmail.com</email></author><category term="알고리즘" /><category term="그리디 알고리즘" /><summary type="html"><![CDATA[🔔 문제]]></summary></entry><entry><title type="html">[논문뿌셔먹기] MaskFormer: Per-Pixel Classification is Not All You Need for Semantic Segmentation</title><link href="http://localhost:4000/%EB%85%BC%EB%AC%B8%EB%BF%8C%EC%85%94%EB%A8%B9%EA%B8%B0/YOLO/" rel="alternate" type="text/html" title="[논문뿌셔먹기] MaskFormer: Per-Pixel Classification is Not All You Need for Semantic Segmentation" /><published>2021-12-29T00:00:00+09:00</published><updated>2024-08-15T00:00:00+09:00</updated><id>http://localhost:4000/%EB%85%BC%EB%AC%B8%EB%BF%8C%EC%85%94%EB%A8%B9%EA%B8%B0/YOLO</id><content type="html" xml:base="http://localhost:4000/%EB%85%BC%EB%AC%B8%EB%BF%8C%EC%85%94%EB%A8%B9%EA%B8%B0/YOLO/"><![CDATA[<blockquote>
  <p>NeurIPS 2021. [<a href="https://arxiv.org/abs/2107.06278">Paper</a>] [<a href="https://bowenc0221.github.io/maskformer/">Page</a>] [<a href="https://github.com/facebookresearch/MaskFormer">Github</a>]<br />
Bowen Cheng, Alexander G. Schwing, Alexander Kirillov<br />
Facebook AI Research (FAIR) | University of Illinois at Urbana-Champaign (UIUC)<br />
13 Jul 2021</p>
</blockquote>]]></content><author><name>Sangwoo Ha</name><email>devswha@gmail.com</email></author><category term="논문뿌셔먹기" /><summary type="html"><![CDATA[Maskformer 논문 리뷰]]></summary></entry><entry><title type="html">Segmentation using Unet with Keras and Jupyter Notebook</title><link href="http://localhost:4000/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/keras-unet/" rel="alternate" type="text/html" title="Segmentation using Unet with Keras and Jupyter Notebook" /><published>2021-09-29T00:00:00+09:00</published><updated>2019-09-29T00:00:00+09:00</updated><id>http://localhost:4000/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/keras-unet</id><content type="html" xml:base="http://localhost:4000/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/keras-unet/"><![CDATA[<blockquote>
  <p>The implementation of biomedical image segmentation with the use of U-Net model with Keras and Jupyter Notebook. The architecture was inspired by <a href="http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/">U-Net: Convolutional Networks for Biomedical Image Segmentation</a>. And I mainly referred to the images and codes of these github: <a href="https://github.com/zhixuhao/unet">zhixuhao github</a> and <a href="https://github.com/ugent-korea/pytorch-unet-segmentation">ugent-korea github</a></p>
</blockquote>

<h2 id="abstract">Abstract</h2>

<p>The author of paper propose a simple and effective end-to-end image segmentation network architecture for medical images.
The proposed network, called U-net, has main three factors for well-training.</p>
<ul>
  <li>U-shaped network structure with two configurations: Contracting and Expanding path</li>
  <li>Training more faster than sliding-windows: Patch units and Overlap-tile</li>
  <li>Data augmentation: Elastic deformation and Weight cross entropy</li>
</ul>

<h2 id="dataset">Dataset</h2>

<p>The dataset we used is Transmission Electron Microscopy (ssTEM) data set of the Drosophila first instar larva ventral nerve cord (VNC), which is dowloaded from <a href="http://brainiac2.mit.edu/isbi_challenge/home">ISBI Challenge: Segmentation of of neural structures in EM stacks</a></p>

<p><img src="http://localhost:4000/assets/images/keras-Unet/ISBI.gif" alt="ISBI" class="align-center" /></p>

<ul>
  <li>Black and white segmentation of membrane and cell with EM(Electron Microscopic) image.</li>
  <li>The data set is a large size of image and few so the data augmentation is needed.</li>
  <li>The data set contains 30 images of size 512x512 for the train, train-labels and test.</li>
  <li>There is no images for test-labels for the ISBI competition.</li>
  <li>If you want to get the evaluation metrics of competition, you should split part of the train data set for testing.</li>
</ul>

<h2 id="overlap-tile">Overlap-tile</h2>

<p><img src="http://localhost:4000/assets/images/keras-Unet/sliding_window.png" alt="sliding_window" class="align-center" /></p>

<p><img src="http://localhost:4000/assets/images/keras-Unet/patch.png" alt="patch" class="align-center" /></p>

<ul>
  <li>Patch method has low overlap ratio so that the speed of detection can be improvement.</li>
  <li>However, as the wide size of patch detect image at once, the performance of context is good but the performance of localization is lower.</li>
  <li>In this paper, the U-net architecture and overlap-tile methods were proposed to solve this localization problem.</li>
</ul>

<p><img src="http://localhost:4000/assets/images/keras-Unet/overlap_tile.png" alt="overlap_tile" class="align-center" /></p>

<p>Simple. Because the EM image is large, sometimes the model of detection input is larger than the patch size (yellow). If so, mirror and fill in the patch area with the empty part.</p>

<h2 id="data-augmenation">Data Augmenation</h2>

<p>We preprocessed the images for data augmentation. Following preprocessing are :</p>
<ul>
  <li>Flip</li>
  <li>Gaussian noise</li>
  <li>Uniform noise</li>
  <li>Brightness</li>
  <li>Elastic deformation</li>
  <li>Crop</li>
  <li>Pad</li>
</ul>

<p>You can easily to understand refer this <a href="https://github.com/ugent-korea/pytorch-unet-segmentation/blob/master/README.md#preprocessing">page</a></p>

<p align="center"><img width="250" height="250" src="/assets/images/keras-Unet/readme_images/original.png" /> <br />Original Image</p>
<table border="0" width="99%">
	<tbody> 
		<tr>		
			<td width="99%" align="center" colspan="4"><strong>Image</strong></td>
		</tr>
		<tr>
			<td width="19%" align="center"> Flip  </td> 
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/flip_vert" /> <br />Vertical  </td> 
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/flip_hori" />  <br />Horizontal</td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/flip_both" /> <br />Both</td>
		</tr>
		<tr>
			<td width="19%" align="center"> Gaussian noise </td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/gn_10" /> <br />Standard Deviation: 10</td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/gn_50" /> <br />Standard Deviation: 50</td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/gn_100" /> <br />Standard Deviation: 100</td>
		</tr>
		<tr>
			<td width="19%" align="center"> Uniform noise </td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/uniform_10" /> <br />Intensity: 10 </td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/un_50" /> <br />Intensity: 50</td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/un_100" /> <br />Intensity: 100</td>
		</tr>
		<tr>
			<td width="19%" align="center"> Brightness </td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/bright_10" /> <br />Intensity: 10</td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/br_50.png" /> <br />Intensity: 20</td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/br_100.png" /> <br />Intensity: 30</td>
		</tr>
		<tr>
			<td width="19%" align="center"> Elastic deformation </td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/ed_10.png" /> <br />Random Deformation: 1</td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/ed_34.png" /> <br />Random Deformation: 2</td>
			<td width="27%" align="center"> <img src="/assets/images/keras-Unet/readme_images/ed_50.png" /> <br />Random Deformation: 3</td>
		</tr>
	</tbody>
</table>
<h3 id="crop-and-pad">Crop and Pad</h3>
<table border="0" width="99%">
	<tbody> 
    	<tr>		
			<td width="99%" align="center" colspan="4"><strong>Crop</strong></td>
	    </tr>
		<tr>
			<td width="25%" align="center"> <img src="/assets/images/keras-Unet/readme_images/c_lb" /> <br />  Left Bottom </td>
			<td width="25%" align="center"> <img src="/assets/images/keras-Unet/readme_images/c_lt" /> <br /> Left Top</td> 
			<td width="25%" align="center"> <img src="/assets/images/keras-Unet/readme_images/c_rb" /> <br /> Right Bottom</td>
			<td width="25%" align="center"> <img src="/assets/images/keras-Unet/readme_images/c_rt" /> <br /> Right Top</td> 
		</tr>
	</tbody>
</table>

<p>Padding process is compulsory after the cropping process as the image has to fit the input size of the U-Net model.</p>

<p>In terms of the padding method, <strong>symmetric padding</strong> was done in which the pad is the reflection of the vector mirrored along the edge of the array. We selected the symmetric padding over several other padding options because it reduces the loss the most.</p>

<p>To help with observation, a <span style="color:black; background-color:yellow;">yellow border</span> is added around the original image: outside the border indicates symmetric padding whereas inside indicates the original image.</p>

<table border="0" width="99%">
	<tbody> 
    	<tr>		
			<td width="99%" align="center" colspan="4"><strong>Pad</strong></td>
	    </tr>
		<tr>
			<td width="25%" align="center"> <img src="/assets/images/keras-Unet/readme_images/p_lb.PNG" /> <br />  Left Bottom </td>
			<td width="25%" align="center"> <img src="/assets/images/keras-Unet/readme_images/p_lt.PNG" /> <br /> Left Top</td> 
			<td width="25%" align="center"> <img src="/assets/images/keras-Unet/readme_images/p_rb.PNG" /> <br /> Right bottom</td>
			<td width="25%" align="center"> <img src="/assets/images/keras-Unet/readme_images/p_rt.PNG" /> <br /> Right Top</td> 
		</tr>
	</tbody>
</table>

<h2 id="network-architecture">Network Architecture</h2>

<p align="center">
    <img src="/assets/images/keras-Unet/unet.png" width="70%" height="70%" />
</p>

<h3 id="contracting-path-fully-convolution">Contracting Path (Fully Convolution)</h3>
<ul>
  <li>Typical convolutional network.</li>
  <li>3x3 convolution layer with max-pooling and drop out</li>
  <li>Extracts the image feature accurately, but reduces the size of the image feature map.</li>
</ul>

<h3 id="expanding-path-deconvolution">Expanding Path (Deconvolution)</h3>
<ul>
  <li>Output segmentation map by upsampling the feature map</li>
  <li>2x2 up-convolution and 3x3 convolution layer with concatenation</li>
  <li>The disadvantage of upsampling process is that the localization information in the image feature map will be lost.</li>
  <li>Therefore, localization information less lost by concatenating the feature map after up-conv with the same level feature map.</li>
  <li>Last one is 1x1 convolution mapping</li>
</ul>

<h2 id="result">Result</h2>

<p align="center">
    <img src="/assets/images/keras-Unet/result.gif" width="100%" height="100%" />
</p>

<h2 id="usage">Usage</h2>
<p>When you download my code, your directory tree should consist of the following</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>keras-Unet/
├── data
    ├── test-volume.tif
    ├── train-labels.tif
    └── train-volume.tif
├── images
├── jupyter.ipynb
├── augmentation.py
├── model.py
├── preprocessing.py
├── README.md
├── train.py
├── utills.py
└── requirement.txt
</code></pre></div></div>
<p>You can change the root directory of data to change the <em>data_path</em> in pre-processing.py and augmentation.py</p>

<p>However, at least three original competition data (test-volume, train-labels, train-volume) should put in the <em>data_path</em></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python3 augmentation.py
<span class="nv">$ </span>python3 preprocessing.py
<span class="nv">$ </span>python3 train.py
</code></pre></div></div>

<p>Easly to use my program just run augmentation-preprocessing-train step.
You can get the prediction.tif for the result.</p>

<p>And you can just run the <strong>jupyter.ipynb</strong> with <a href="https://jupyter.org/">jupyter notebook</a> to see how U-net works.</p>

<h2 id="github-link">Github link</h2>
<p><a href="https://github.com/devswha/keras-Unet">Segmentation using Unet with Keras and Jupyter Notebook</a></p>]]></content><author><name>Sangwoo Ha</name><email>devswha@gmail.com</email></author><category term="프로그래밍" /><category term="Unet" /><summary type="html"><![CDATA[The implementation of biomedical image segmentation with the use of U-Net model with Keras and Jupyter Notebook]]></summary></entry></feed>